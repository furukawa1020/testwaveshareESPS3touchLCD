#include "llm_handler.h"

LLMHandler::LLMHandler() {
    llm_type = LLM_NONE;
    history_count = 0;
    system_prompt = LLMConfig::KIRBY_SYSTEM_PROMPT;
    tiny_llm = nullptr;
    simple_responder = nullptr;
}

LLMHandler::~LLMHandler() {
    if (http_client.connected()) {
        http_client.end();
    }
    if (tiny_llm) {
        delete tiny_llm;
    }
    if (simple_responder) {
        delete simple_responder;
    }
}

bool LLMHandler::connectWiFi(const char* ssid, const char* password) {
    Serial.print("WiFiæ¥ç¶šä¸­: ");
    Serial.println(ssid);
    
    WiFi.mode(WIFI_STA);
    WiFi.begin(ssid, password);
    
    int attempts = 0;
    while (WiFi.status() != WL_CONNECTED && attempts < 30) {
        delay(500);
        Serial.print(".");
        attempts++;
    }
    
    if (WiFi.status() == WL_CONNECTED) {
        Serial.println("\nWiFiæ¥ç¶šæˆåŠŸ!");
        Serial.print("IP: ");
        Serial.println(WiFi.localIP());
        return true;
    } else {
        Serial.println("\nWiFiæ¥ç¶šå¤±æ•—");
        return false;
    }
}

bool LLMHandler::isConnected() {
    return WiFi.status() == WL_CONNECTED;
}

void LLMHandler::setLLMType(LLMType type) {
    llm_type = type;
}

void LLMHandler::setAPIKey(const String& key) {
    api_key = key;
}

void LLMHandler::setEndpoint(const String& endpoint) {
    api_endpoint = endpoint;
}

void LLMHandler::setModelName(const String& model) {
    model_name = model;
}

void LLMHandler::setSystemPrompt(const String& prompt) {
    system_prompt = prompt;
}

void LLMHandler::setupKirbyPersonality() {
    system_prompt = LLMConfig::KIRBY_SYSTEM_PROMPT;
}

void LLMHandler::setupCuteAssistant() {
    system_prompt = 
        "ã‚ãªãŸã¯ã¨ã£ã¦ã‚‚ã‹ã‚ã„ã„AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "çŸ­ãã€æ¥½ã—ãã€è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚";
}

bool LLMHandler::initTinyLLM() {
    Serial.println("TinyLLMåˆæœŸåŒ–ä¸­...");
    
    if (tiny_llm) {
        delete tiny_llm;
    }
    
    tiny_llm = new TinyLLM();
    if (!tiny_llm->init()) {
        Serial.println("TinyLLMåˆæœŸåŒ–å¤±æ•—");
        delete tiny_llm;
        tiny_llm = nullptr;
        return false;
    }
    
    Serial.println("TinyLLMåˆæœŸåŒ–å®Œäº†!");
    return true;
}

bool LLMHandler::initSimpleResponder() {
    Serial.println("SimpleResponderåˆæœŸåŒ–ä¸­...");
    
    if (simple_responder) {
        delete simple_responder;
    }
    
    simple_responder = new SimpleResponder();
    simple_responder->init();
    
    Serial.println("SimpleResponderåˆæœŸåŒ–å®Œäº†!");
    return true;
}

bool LLMHandler::loadTinyModel(const char* path) {
    if (!tiny_llm) {
        Serial.println("TinyLLMãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“");
        return false;
    }
    
    return tiny_llm->loadModelFromSD(path);
}

String LLMHandler::chat(const String& user_message) {
    if (llm_type == LLM_NONE) {
        return "LLMãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“";
    }
    
    // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã¯WiFiå¿…è¦
    if (!isConnected() && 
        llm_type != LLM_TINY_LOCAL && 
        llm_type != LLM_RULE_BASED) {
        return "WiFiã«æ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“";
    }
    
    Serial.print("ãƒ¦ãƒ¼ã‚¶ãƒ¼: ");
    Serial.println(user_message);
    
    uint32_t start_time = millis();
    String response;
    
    switch (llm_type) {
        case LLM_CLOUD_OPENAI:
        case LLM_CLOUD_CLAUDE:
        case LLM_CLOUD_GEMINI:
            response = sendCloudRequest(user_message);
            break;
            
        case LLM_LOCAL_SERVER:
            response = sendLocalRequest(user_message);
            break;
            
        case LLM_TINY_LOCAL:
            response = processTinyLocal(user_message);
            break;
            
        case LLM_RULE_BASED:
            response = processRuleBased(user_message);
            break;
            
        default:
            response = "æœªå¯¾å¿œã®LLMã‚¿ã‚¤ãƒ—ã§ã™";
            break;
    }
    
    uint32_t elapsed = millis() - start_time;
    
    if (response.length() > 0) {
        addToHistory(user_message, response);
    }
    
    Serial.print("ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: ");
    Serial.println(response);
    Serial.printf("å¿œç­”æ™‚é–“: %dms\n", elapsed);
    
    return response;
}

void LLMHandler::clearHistory() {
    history_count = 0;
    for (int i = 0; i < MAX_HISTORY * 2; i++) {
        conversation_history[i] = "";
    }
}

void LLMHandler::addToHistory(const String& user_msg, const String& assistant_msg) {
    if (history_count >= MAX_HISTORY) {
        // å¤ã„å±¥æ­´ã‚’å‰Šé™¤
        for (int i = 0; i < (MAX_HISTORY - 1) * 2; i++) {
            conversation_history[i] = conversation_history[i + 2];
        }
        history_count = MAX_HISTORY - 1;
    }
    
    int idx = history_count * 2;
    conversation_history[idx] = user_msg;
    conversation_history[idx + 1] = assistant_msg;
    history_count++;
}

String LLMHandler::buildPrompt(const String& current_message) {
    String prompt = system_prompt + "\n\n";
    
    // ä¼šè©±å±¥æ­´ã‚’è¿½åŠ 
    for (int i = 0; i < history_count; i++) {
        int idx = i * 2;
        prompt += "User: " + conversation_history[idx] + "\n";
        prompt += "Assistant: " + conversation_history[idx + 1] + "\n";
    }
    
    prompt += "User: " + current_message + "\nAssistant: ";
    return prompt;
}

String LLMHandler::sendCloudRequest(const String& message) {
    if (!http_client.begin(api_endpoint)) {
        return "HTTPæ¥ç¶šã‚¨ãƒ©ãƒ¼";
    }
    
    http_client.setTimeout(15000); // 15ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    
    // ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
    http_client.addHeader("Content-Type", "application/json");
    
    if (llm_type == LLM_CLOUD_OPENAI) {
        http_client.addHeader("Authorization", "Bearer " + api_key);
    } else if (llm_type == LLM_CLOUD_CLAUDE) {
        http_client.addHeader("x-api-key", api_key);
        http_client.addHeader("anthropic-version", "2023-06-01");
    }
    
    // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ä½œæˆ
    DynamicJsonDocument doc(4096);
    
    if (llm_type == LLM_CLOUD_OPENAI) {
        doc["model"] = model_name;
        JsonArray messages = doc.createNestedArray("messages");
        
        JsonObject system_msg = messages.createNestedObject();
        system_msg["role"] = "system";
        system_msg["content"] = system_prompt;
        
        // å±¥æ­´è¿½åŠ 
        for (int i = 0; i < history_count; i++) {
            int idx = i * 2;
            JsonObject user_msg = messages.createNestedObject();
            user_msg["role"] = "user";
            user_msg["content"] = conversation_history[idx];
            
            JsonObject asst_msg = messages.createNestedObject();
            asst_msg["role"] = "assistant";
            asst_msg["content"] = conversation_history[idx + 1];
        }
        
        JsonObject current_msg = messages.createNestedObject();
        current_msg["role"] = "user";
        current_msg["content"] = message;
        
        doc["max_tokens"] = 150;
        doc["temperature"] = 0.8;
    }
    
    String request_body;
    serializeJson(doc, request_body);
    
    Serial.println("ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...");
    int http_code = http_client.POST(request_body);
    
    String response;
    if (http_code > 0) {
        if (http_code == HTTP_CODE_OK) {
            response = http_client.getString();
            
            // ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            if (llm_type == LLM_CLOUD_OPENAI) {
                response = parseOpenAIResponse(response);
            } else if (llm_type == LLM_CLOUD_CLAUDE) {
                response = parseClaudeResponse(response);
            } else if (llm_type == LLM_CLOUD_GEMINI) {
                response = parseGeminiResponse(response);
            }
        } else {
            response = "HTTPã‚¨ãƒ©ãƒ¼: " + String(http_code);
        }
    } else {
        response = "æ¥ç¶šã‚¨ãƒ©ãƒ¼";
    }
    
    http_client.end();
    return response;
}

String LLMHandler::sendLocalRequest(const String& message) {
    if (!http_client.begin(api_endpoint)) {
        return "ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚¨ãƒ©ãƒ¼";
    }
    
    http_client.setTimeout(30000); // 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    http_client.addHeader("Content-Type", "application/json");
    
    // Ollamaå½¢å¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    DynamicJsonDocument doc(2048);
    doc["model"] = model_name;
    doc["prompt"] = buildPrompt(message);
    doc["stream"] = false;
    
    String request_body;
    serializeJson(doc, request_body);
    
    int http_code = http_client.POST(request_body);
    
    String response;
    if (http_code > 0) {
        if (http_code == HTTP_CODE_OK) {
            response = http_client.getString();
            response = parseOllamaResponse(response);
        } else {
            response = "ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: " + String(http_code);
        }
    } else {
        response = "æ¥ç¶šã‚¨ãƒ©ãƒ¼";
    }
    
    http_client.end();
    return response;
}

String LLMHandler::processTinyLocal(const String& message) {
    if (!tiny_llm) {
        Serial.println("TinyLLMãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“");
        return "ã”ã‚ã‚“ã­ã€ä»Šã¯è€ƒãˆã‚‰ã‚Œãªã„ã®... ğŸ˜¢";
    }
    
    if (!tiny_llm->isModelLoaded()) {
        Serial.println("ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“");
        return "ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãªã„ã®... ã”ã‚ã‚“ã­! ğŸ’¦";
    }
    
    // ä¼šè©±å±¥æ­´ã‚’å«ã‚ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
    String context = buildPrompt(message);
    
    // TinyLLMã§æ¨è«–
    String response = tiny_llm->chat(message, context);
    
    // ç©ºã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if (response.length() == 0) {
        return "ã†ãƒ¼ã‚“ã€ãªã‚“ã¦è¨€ãˆã°ã„ã„ã‹ãª... ğŸ¤”";
    }
    
    return response;
}

String LLMHandler::processRuleBased(const String& message) {
    if (!simple_responder) {
        initSimpleResponder();
    }
    
    return simple_responder->respond(message);
}

String LLMHandler::parseOpenAIResponse(const String& response) {
    DynamicJsonDocument doc(4096);
    DeserializationError error = deserializeJson(doc, response);
    
    if (error) {
        return "JSONè§£æã‚¨ãƒ©ãƒ¼";
    }
    
    if (doc.containsKey("choices")) {
        return doc["choices"][0]["message"]["content"].as<String>();
    }
    
    return "å¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ";
}

String LLMHandler::parseClaudeResponse(const String& response) {
    DynamicJsonDocument doc(4096);
    DeserializationError error = deserializeJson(doc, response);
    
    if (error) {
        return "JSONè§£æã‚¨ãƒ©ãƒ¼";
    }
    
    if (doc.containsKey("content")) {
        return doc["content"][0]["text"].as<String>();
    }
    
    return "å¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ";
}

String LLMHandler::parseGeminiResponse(const String& response) {
    DynamicJsonDocument doc(4096);
    DeserializationError error = deserializeJson(doc, response);
    
    if (error) {
        return "JSONè§£æã‚¨ãƒ©ãƒ¼";
    }
    
    if (doc.containsKey("candidates")) {
        return doc["candidates"][0]["content"]["parts"][0]["text"].as<String>();
    }
    
    return "å¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ";
}

String LLMHandler::parseOllamaResponse(const String& response) {
    DynamicJsonDocument doc(4096);
    DeserializationError error = deserializeJson(doc, response);
    
    if (error) {
        return "JSONè§£æã‚¨ãƒ©ãƒ¼";
    }
    
    if (doc.containsKey("response")) {
        return doc["response"].as<String>();
    }
    
    return "å¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ";
}
