#include "llm_handler.h"

LLMHandler::LLMHandler() {
    llm_type = LLM_NONE;
    history_count = 0;
    system_prompt = LLMConfig::KIRBY_SYSTEM_PROMPT;
}

LLMHandler::~LLMHandler() {
    if (http_client.connected()) {
        http_client.end();
    }
}

bool LLMHandler::connectWiFi(const char* ssid, const char* password) {
    Serial.print("WiFiæ¥ç¶šä¸­: ");
    Serial.println(ssid);
    
    WiFi.mode(WIFI_STA);
    WiFi.begin(ssid, password);
    
    int attempts = 0;
    while (WiFi.status() != WL_CONNECTED && attempts < 30) {
        delay(500);
        Serial.print(".");
        attempts++;
    }
    
    if (WiFi.status() == WL_CONNECTED) {
        Serial.println("\nWiFiæ¥ç¶šæˆåŠŸ!");
        Serial.print("IP: ");
        Serial.println(WiFi.localIP());
        return true;
    } else {
        Serial.println("\nWiFiæ¥ç¶šå¤±æ•—");
        return false;
    }
}

bool LLMHandler::isConnected() {
    return WiFi.status() == WL_CONNECTED;
}

void LLMHandler::setLLMType(LLMType type) {
    llm_type = type;
}

void LLMHandler::setAPIKey(const String& key) {
    api_key = key;
}

void LLMHandler::setEndpoint(const String& endpoint) {
    api_endpoint = endpoint;
}

void LLMHandler::setModelName(const String& model) {
    model_name = model;
}

void LLMHandler::setSystemPrompt(const String& prompt) {
    system_prompt = prompt;
}

void LLMHandler::setupKirbyPersonality() {
    system_prompt = LLMConfig::KIRBY_SYSTEM_PROMPT;
}

void LLMHandler::setupCuteAssistant() {
    system_prompt = 
        "ã‚ãªãŸã¯ã¨ã£ã¦ã‚‚ã‹ã‚ã„ã„AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "çŸ­ãã€æ¥½ã—ãã€è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚";
}

String LLMHandler::chat(const String& user_message) {
    if (llm_type == LLM_NONE) {
        return "LLMãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“";
    }
    
    if (!isConnected() && llm_type != LLM_MICRO_LOCAL) {
        return "WiFiã«æ¥ç¶šã•ã‚Œã¦ã„ã¾ã›ã‚“";
    }
    
    Serial.print("ãƒ¦ãƒ¼ã‚¶ãƒ¼: ");
    Serial.println(user_message);
    
    String response;
    
    switch (llm_type) {
        case LLM_CLOUD_OPENAI:
        case LLM_CLOUD_CLAUDE:
        case LLM_CLOUD_GEMINI:
            response = sendCloudRequest(user_message);
            break;
            
        case LLM_LOCAL_SERVER:
            response = sendLocalRequest(user_message);
            break;
            
        case LLM_MICRO_LOCAL:
            response = processMicroLocal(user_message);
            break;
            
        default:
            response = "æœªå¯¾å¿œã®LLMã‚¿ã‚¤ãƒ—ã§ã™";
            break;
    }
    
    if (response.length() > 0) {
        addToHistory(user_message, response);
    }
    
    Serial.print("ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: ");
    Serial.println(response);
    
    return response;
}

void LLMHandler::clearHistory() {
    history_count = 0;
    for (int i = 0; i < MAX_HISTORY * 2; i++) {
        conversation_history[i] = "";
    }
}

void LLMHandler::addToHistory(const String& user_msg, const String& assistant_msg) {
    if (history_count >= MAX_HISTORY) {
        // å¤ã„å±¥æ­´ã‚’å‰Šé™¤
        for (int i = 0; i < (MAX_HISTORY - 1) * 2; i++) {
            conversation_history[i] = conversation_history[i + 2];
        }
        history_count = MAX_HISTORY - 1;
    }
    
    int idx = history_count * 2;
    conversation_history[idx] = user_msg;
    conversation_history[idx + 1] = assistant_msg;
    history_count++;
}

String LLMHandler::buildPrompt(const String& current_message) {
    String prompt = system_prompt + "\n\n";
    
    // ä¼šè©±å±¥æ­´ã‚’è¿½åŠ 
    for (int i = 0; i < history_count; i++) {
        int idx = i * 2;
        prompt += "User: " + conversation_history[idx] + "\n";
        prompt += "Assistant: " + conversation_history[idx + 1] + "\n";
    }
    
    prompt += "User: " + current_message + "\nAssistant: ";
    return prompt;
}

String LLMHandler::sendCloudRequest(const String& message) {
    if (!http_client.begin(api_endpoint)) {
        return "HTTPæ¥ç¶šã‚¨ãƒ©ãƒ¼";
    }
    
    http_client.setTimeout(15000); // 15ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    
    // ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
    http_client.addHeader("Content-Type", "application/json");
    
    if (llm_type == LLM_CLOUD_OPENAI) {
        http_client.addHeader("Authorization", "Bearer " + api_key);
    } else if (llm_type == LLM_CLOUD_CLAUDE) {
        http_client.addHeader("x-api-key", api_key);
        http_client.addHeader("anthropic-version", "2023-06-01");
    }
    
    // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ä½œæˆ
    DynamicJsonDocument doc(4096);
    
    if (llm_type == LLM_CLOUD_OPENAI) {
        doc["model"] = model_name;
        JsonArray messages = doc.createNestedArray("messages");
        
        JsonObject system_msg = messages.createNestedObject();
        system_msg["role"] = "system";
        system_msg["content"] = system_prompt;
        
        // å±¥æ­´è¿½åŠ 
        for (int i = 0; i < history_count; i++) {
            int idx = i * 2;
            JsonObject user_msg = messages.createNestedObject();
            user_msg["role"] = "user";
            user_msg["content"] = conversation_history[idx];
            
            JsonObject asst_msg = messages.createNestedObject();
            asst_msg["role"] = "assistant";
            asst_msg["content"] = conversation_history[idx + 1];
        }
        
        JsonObject current_msg = messages.createNestedObject();
        current_msg["role"] = "user";
        current_msg["content"] = message;
        
        doc["max_tokens"] = 150;
        doc["temperature"] = 0.8;
    }
    
    String request_body;
    serializeJson(doc, request_body);
    
    Serial.println("ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...");
    int http_code = http_client.POST(request_body);
    
    String response;
    if (http_code > 0) {
        if (http_code == HTTP_CODE_OK) {
            response = http_client.getString();
            
            // ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            if (llm_type == LLM_CLOUD_OPENAI) {
                response = parseOpenAIResponse(response);
            } else if (llm_type == LLM_CLOUD_CLAUDE) {
                response = parseClaudeResponse(response);
            } else if (llm_type == LLM_CLOUD_GEMINI) {
                response = parseGeminiResponse(response);
            }
        } else {
            response = "HTTPã‚¨ãƒ©ãƒ¼: " + String(http_code);
        }
    } else {
        response = "æ¥ç¶šã‚¨ãƒ©ãƒ¼";
    }
    
    http_client.end();
    return response;
}

String LLMHandler::sendLocalRequest(const String& message) {
    if (!http_client.begin(api_endpoint)) {
        return "ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚¨ãƒ©ãƒ¼";
    }
    
    http_client.setTimeout(30000); // 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    http_client.addHeader("Content-Type", "application/json");
    
    // Ollamaå½¢å¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    DynamicJsonDocument doc(2048);
    doc["model"] = model_name;
    doc["prompt"] = buildPrompt(message);
    doc["stream"] = false;
    
    String request_body;
    serializeJson(doc, request_body);
    
    int http_code = http_client.POST(request_body);
    
    String response;
    if (http_code > 0) {
        if (http_code == HTTP_CODE_OK) {
            response = http_client.getString();
            response = parseOllamaResponse(response);
        } else {
            response = "ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: " + String(http_code);
        }
    } else {
        response = "æ¥ç¶šã‚¨ãƒ©ãƒ¼";
    }
    
    http_client.end();
    return response;
}

String LLMHandler::processMicroLocal(const String& message) {
    // è¶…è»½é‡ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®å¿œç­”
    // ESP32-S3ã®ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ã®ãŸã‚ã€å®Œå…¨ãªLLMã¯ä¸å¯èƒ½
    
    String msg_lower = message;
    msg_lower.toLowerCase();
    
    if (msg_lower.indexOf("ã“ã‚“ã«ã¡ã¯") >= 0 || msg_lower.indexOf("hello") >= 0) {
        return "ã‚„ã£ã»ãƒ¼! å…ƒæ°—ã ã‚ˆ! ğŸ€";
    } else if (msg_lower.indexOf("å…ƒæ°—") >= 0) {
        return "ã†ã‚“! ã¨ã£ã¦ã‚‚å…ƒæ°—ã ã‚ˆ! âœ¨";
    } else if (msg_lower.indexOf("ã‚ã‚ŠãŒã¨ã†") >= 0) {
        return "ã©ã†ã„ãŸã—ã¾ã—ã¦! ğŸ’•";
    } else if (msg_lower.indexOf("ã‹ã‚ã„ã„") >= 0) {
        return "ãˆã¸ã¸ã€ã‚ã‚ŠãŒã¨ã†! (*Â´â–½`*) ğŸ’—";
    } else if (msg_lower.indexOf("åå‰") >= 0) {
        return "ã¼ãã®åå‰ã¯ã‚«ãƒ“ã¡ã‚ƒã‚“ã ã‚ˆ! ğŸŒ¸";
    } else if (msg_lower.indexOf("å¥½ã") >= 0) {
        return "ã‚ãƒ¼ã„! ã¼ãã‚‚å¤§å¥½ãã ã‚ˆ! ğŸ’–";
    } else if (msg_lower.indexOf("éŠ") >= 0) {
        return "éŠã¼ã†éŠã¼ã†! ä½•ã—ã¦éŠã¶? ğŸ®";
    } else if (msg_lower.indexOf("ã•ã‚ˆã†ãªã‚‰") >= 0 || msg_lower.indexOf("bye") >= 0) {
        return "ã¾ãŸã­! ãƒã‚¤ãƒã‚¤! ğŸ‘‹âœ¨";
    } else {
        return "ãµã‚€ãµã‚€ã€ãªã‚‹ã»ã©ã­! ğŸ˜Š";
    }
}

String LLMHandler::parseOpenAIResponse(const String& response) {
    DynamicJsonDocument doc(4096);
    DeserializationError error = deserializeJson(doc, response);
    
    if (error) {
        return "JSONè§£æã‚¨ãƒ©ãƒ¼";
    }
    
    if (doc.containsKey("choices")) {
        return doc["choices"][0]["message"]["content"].as<String>();
    }
    
    return "å¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ";
}

String LLMHandler::parseClaudeResponse(const String& response) {
    DynamicJsonDocument doc(4096);
    DeserializationError error = deserializeJson(doc, response);
    
    if (error) {
        return "JSONè§£æã‚¨ãƒ©ãƒ¼";
    }
    
    if (doc.containsKey("content")) {
        return doc["content"][0]["text"].as<String>();
    }
    
    return "å¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ";
}

String LLMHandler::parseGeminiResponse(const String& response) {
    DynamicJsonDocument doc(4096);
    DeserializationError error = deserializeJson(doc, response);
    
    if (error) {
        return "JSONè§£æã‚¨ãƒ©ãƒ¼";
    }
    
    if (doc.containsKey("candidates")) {
        return doc["candidates"][0]["content"]["parts"][0]["text"].as<String>();
    }
    
    return "å¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ";
}

String LLMHandler::parseOllamaResponse(const String& response) {
    DynamicJsonDocument doc(4096);
    DeserializationError error = deserializeJson(doc, response);
    
    if (error) {
        return "JSONè§£æã‚¨ãƒ©ãƒ¼";
    }
    
    if (doc.containsKey("response")) {
        return doc["response"].as<String>();
    }
    
    return "å¿œç­”ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ";
}
